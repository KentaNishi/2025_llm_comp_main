# トークン長分析レポート

**作成日**: 2026-02-07
**分析対象**: 全SFTデータセット（23,441サンプル）

## エグゼクティブサマリー

現在の設定（`SFT_MAX_SEQ_LEN=512`）では、**全データの64.5%しかカバーできず、35.5%が切り捨てられます**。

### 重要な発見

1. **データセット間で大きな長さの差異**:
   - **daichira系**: 平均900-1000トークン（長い）
   - **u-10bei系**: 平均320トークン（短い、CoT含む）

2. **推奨値**:
   - **1024トークン**: 75%カバー（バランス型、推奨）
   - **2048トークン**: 98%カバー（ほぼ完全、メモリに余裕があれば推奨）

## 全体統計

```
サンプル数:     23,441
平均:          635.5 トークン
中央値:        305.0 トークン
標準偏差:      572.2 トークン
最小値:        110 トークン
最大値:        2,341 トークン

パーセンタイル:
  50%:         305 トークン
  75%:         1,005 トークン
  90%:         1,639 トークン
  95%:         1,859 トークン
  99%:         2,125 トークン
```

## 各MAX_SEQ_LENでのカバー率

| MAX_SEQ_LEN | カバー率 | 切り捨て率 | 評価 |
|-------------|----------|-----------|------|
| 256 | 32.1% | 67.9% | ❌ 不十分 |
| 512 | **64.5%** | **35.5%** | ⚠️ 現在の設定 |
| 768 | 70.7% | 29.3% | △ 改善の余地 |
| 1024 | **75.5%** | **24.5%** | ✓ バランス良好 |
| 1536 | 87.8% | 12.2% | ✓ 良好 |
| 2048 | **98.1%** | **1.9%** | ✓✓ ほぼ完全 |

## データセット別の詳細分析

### 1. daichira__structured-3k-mix-sft (3,000サンプル)

**概要**: 5フォーマット均等配分、構造化データ変換

```
平均:          998.8 トークン
中央値:        1,067.5 トークン
95%:           1,975 トークン

512トークンでのカバー率: 35.7% (64.3%が切り捨て)
1024トークンでのカバー率: 47.6%
2048トークンでのカバー率: 96.8%
```

**カテゴリ別内訳**:
| カテゴリ | サンプル数 | 平均 | 中央値 | 95% |
|---------|-----------|------|--------|-----|
| C_TOML | 600 | 277 | 277 | 294 |
| C_YAML | 400 | 790 | 516 | 1,837 |
| C_CSV | 600 | 1,059 | 1,175 | 1,895 |
| C_JSON | 600 | 1,126 | 1,205 | 1,884 |
| C_XML | 800 | **1,504** | 1,477 | **2,120** |

**特徴**:
- C_TOMLは非常に短い（277トークン）
- C_XMLが最も長く、平均1,504トークン
- 512トークンでは**64.3%が切り捨て**

### 2. daichira__structured-5k-mix-sft (5,000サンプル)

**概要**: 13種類の変換タスク、YAML/TOML重点

```
平均:          924.9 トークン
中央値:        966.0 トークン
95%:           1,969 トークン

512トークンでのカバー率: 42.5% (57.5%が切り捨て)
1024トークンでのカバー率: 53.1%
2048トークンでのカバー率: 97.3%
```

**カテゴリ別内訳**:
| カテゴリ | サンプル数 | 平均 | 中央値 | 95% |
|---------|-----------|------|--------|-----|
| C_TOML | 1,500 | 278 | 278 | 295 |
| C_YAML | 1,100 | 945 | 1,010 | 1,830 |
| C_CSV | 500 | 1,038 | 1,112 | 1,913 |
| C_JSON | 500 | 1,109 | 1,170 | 1,932 |
| C_XML | 1,400 | **1,497** | 1,488 | **2,117** |

**特徴**:
- TOMLが30%（1,500サンプル）で平均が短い
- XMLが最も長く、1,400サンプル
- 512トークンでは**57.5%が切り捨て**

### 3. daichira__structured-hard-sft-4k (4,000サンプル)

**概要**: 高難度タスクのみ（4タスク×1,000）

```
平均:          895.6 トークン
中央値:        516.5 トークン
95%:           2,050 トークン

512トークンでのカバー率: 50.0% (ちょうど半分が切り捨て)
1024トークンでのカバー率: 54.9%
2048トークンでのカバー率: 94.9%
```

**カテゴリ別内訳**:
| カテゴリ | サンプル数 | 平均 | 中央値 | 95% |
|---------|-----------|------|--------|-----|
| C_YAML | 1,000 | 235 | 235 | 253 |
| C_TOML | 1,000 | 278 | 278 | 296 |
| C_XML | 2,000 | **1,535** | 1,528 | **2,139** |

**特徴**:
- YAML/TOMLが短い（text_to_*抽出タスク）
- XMLが長い（json_to_xml変換タスク）
- 512トークンで**ちょうど50%が切り捨て**

### 4. u-10bei__structured_data_with_cot_dataset_512_v4 (5,758サンプル)

**概要**: CoT推論付き、512トークン制限版

```
平均:          317.4 トークン
中央値:        265.0 トークン
95%:           604 トークン

512トークンでのカバー率: 86.9% (13.1%が切り捨て)
768トークンでのカバー率: 99.6%
1024トークンでのカバー率: 100%
```

**フォーマット別内訳**:
| フォーマット | サンプル数 | 平均 | 中央値 | 95% |
|-------------|-----------|------|--------|-----|
| csv | 1,160 | 301 | 247 | 574 |
| json | 1,137 | 328 | 263 | 620 |
| toml | 1,141 | 306 | 259 | 580 |
| xml | 1,166 | 350 | 279 | 639 |
| yaml | 1,154 | 302 | 254 | 565 |

**特徴**:
- 5フォーマットがほぼ均等（各約1,150サンプル）
- 512トークンで**86.9%をカバー**（良好）
- v4として意図的に512トークン以下に収まるよう設計されている

### 5. u-10bei__structured_data_with_cot_dataset_512_v5 (5,683サンプル)

**概要**: 最新版、ランダムスキーマ + minified/sorted制約

```
平均:          328.3 トークン
中央値:        272.0 トークン
95%:           621 トークン

512トークンでのカバー率: 86.5% (13.5%が切り捨て)
768トークンでのカバー率: 98.0%
1024トークンでのカバー率: 99.5%
```

**フォーマット別内訳**:
| フォーマット | サンプル数 | 平均 | 中央値 | 95% |
|-------------|-----------|------|--------|-----|
| csv | 1,141 | 316 | 268 | 602 |
| json | 1,102 | 328 | 280 | 621 |
| toml | 1,161 | 324 | 270 | 619 |
| xml | 1,115 | 355 | 295 | 643 |
| yaml | 1,164 | 318 | 258 | 600 |

**特徴**:
- v4とほぼ同じ傾向
- 512トークンで**86.5%をカバー**
- 最大値が1,667トークン（v4より長いサンプルあり）

## データセット選択による推奨設定

### シナリオ1: u-10bei系のみ使用

```bash
SFT_MAX_SEQ_LEN=512   # 推奨（86-87%カバー）
SFT_MAX_SEQ_LEN=768   # 理想（98-100%カバー）
```

**理由**:
- v4/v5は512トークン制限を考慮して設計されている
- 512で86.5%以上カバー
- 768で98%以上カバー

### シナリオ2: daichira系のみ使用

```bash
SFT_MAX_SEQ_LEN=1024  # 最低限（約50-55%カバー）
SFT_MAX_SEQ_LEN=2048  # 推奨（95-97%カバー）
```

**理由**:
- 512では50-64%が切り捨てられる
- 1024でも約半分しかカバーできない
- 2048で初めて95%以上をカバー

### シナリオ3: 両方を混合使用（現実的）

```bash
SFT_MAX_SEQ_LEN=1024  # バランス型推奨
SFT_MAX_SEQ_LEN=1536  # 高カバー率型
SFT_MAX_SEQ_LEN=2048  # 完全カバー型
```

**比較表**:
| 設定 | 全体カバー率 | daichira系 | u-10bei系 | メモリ | 判定 |
|------|-------------|-----------|----------|--------|------|
| 512 | 64.5% | 35-50% | 86.5% | 低 | ❌ 不十分 |
| 1024 | **75.5%** | 47-55% | 99.5% | 中 | ✓ **推奨** |
| 1536 | 87.8% | 75% | 99.9% | 中高 | ✓ 良好 |
| 2048 | **98.1%** | 95-97% | 100% | 高 | ✓✓ **理想** |

## メモリとトレードオフの考慮

### メモリ使用量の概算

**前提**:
- モデル: Llama-3.2-1B-Instruct
- バッチサイズ: 2 (per device)
- 勾配累積: 8
- LoRA: r=64

**相対的メモリ使用量**:
| MAX_SEQ_LEN | 相対メモリ | 絶対値（概算） |
|-------------|-----------|--------------|
| 512 | 1.0x | ベースライン |
| 768 | 1.5x | +50% |
| 1024 | 2.0x | +100% |
| 1536 | 3.0x | +200% |
| 2048 | 4.0x | +300% |

### トレードオフ分析

#### オプションA: MAX_SEQ_LEN=512（現状維持）
**メリット**:
- メモリ効率が最高
- u-10bei系データで良好なパフォーマンス
- 学習速度が速い

**デメリット**:
- daichira系の64%が切り捨て
- 構造化データ変換の精度が低下する可能性
- 全体の35.5%がロス

**推奨**: ❌ 全データ使用には不適切

#### オプションB: MAX_SEQ_LEN=1024（バランス型・推奨）
**メリット**:
- 全体の75.5%をカバー
- daichira系でも約半分がフル利用可能
- u-10bei系はほぼ完全カバー（99.5%）
- メモリは2倍だが実用的

**デメリット**:
- daichira系の約半分は切り捨て
- メモリ使用量が2倍

**推奨**: ✓✓ **メモリとカバー率のバランスが最良**

#### オプションC: MAX_SEQ_LEN=1536（高カバー型）
**メリット**:
- 全体の87.8%をカバー
- daichira系でも75%カバー
- ほぼすべてのu-10bei系をカバー

**デメリット**:
- メモリ使用量が3倍
- 学習速度が低下

**推奨**: △ メモリに余裕があれば検討

#### オプションD: MAX_SEQ_LEN=2048（完全カバー型）
**メリット**:
- 全体の98.1%をカバー
- daichira系で95-97%カバー
- データロスがほぼゼロ

**デメリット**:
- メモリ使用量が4倍
- 学習速度が大幅に低下
- OOM（メモリ不足）のリスク

**推奨**: △ 十分なリソースがあれば理想的

## 段階的学習戦略の提案

### 戦略1: データセット分離学習

```bash
# Phase 1: u-10bei系のみ（512トークン）
SFT_MAX_SEQ_LEN=512
# データ: v4 + v5のみ使用

# Phase 2: daichira系のみ（2048トークン）
SFT_MAX_SEQ_LEN=2048
# データ: daichira全データ使用
```

**メリット**: 各データセットに最適な設定
**デメリット**: 2回の学習が必要

### 戦略2: 混合学習（推奨）

```bash
# すべてのデータを1024トークンで学習
SFT_MAX_SEQ_LEN=1024
```

**メリット**: 1回の学習で完結、75%以上カバー
**デメリット**: 約25%がロス

### 戦略3: フィルタリング + 最適化

```bash
# 1024トークン以下のサンプルのみ使用
SFT_MAX_SEQ_LEN=1024
# フィルタリング後: 約17,600サンプル（75%）
```

**メリット**: データロスなし、メモリ効率的
**デメリット**: データ量が減少、長いサンプルを学習できない

## 最終推奨

### 推奨設定

```bash
# execution.envに設定
SFT_MAX_SEQ_LEN=1024  # 512から変更
```

**理由**:
1. 全体の75.5%をカバー（512の64.5%から改善）
2. メモリ使用量は2倍だが、一般的なGPUで実用的
3. u-10bei系は99.5%カバー（ほぼ完全）
4. daichira系でも約半分がフル活用可能
5. バランスが最良

### 代替案（リソースに応じて）

**メモリが限られている場合**:
```bash
SFT_MAX_SEQ_LEN=512  # 現状維持
# + u-10bei系データのみ使用
```

**メモリに余裕がある場合**:
```bash
SFT_MAX_SEQ_LEN=2048  # 理想的
# 全データの98%をカバー
```

## アクションアイテム

1. **即座に実行**:
   - [ ] `execution.env`で`SFT_MAX_SEQ_LEN=1024`に変更
   - [ ] 学習スクリプトでメモリ使用量をモニタリング
   - [ ] OOMが発生する場合は512に戻す

2. **検証**:
   - [ ] 小規模テストラン（SFT_MAX_STEPS=10）でメモリ確認
   - [ ] バッチサイズの調整が必要か確認
   - [ ] 勾配累積ステップの調整を検討

3. **最適化**:
   - [ ] 1024でOOMの場合、バッチサイズを1に削減
   - [ ] または768トークンで妥協（70.7%カバー）
   - [ ] または長いサンプルをフィルタリング

4. **評価**:
   - [ ] 1024トークンで学習後、精度を評価
   - [ ] 512との比較実験を実施
   - [ ] 切り捨てられたデータの影響を分析

## 参考: カテゴリ別の詳細統計

### daichira系のタスク別平均トークン数

| タスク | 平均 | 推奨MAX_SEQ_LEN |
|-------|------|----------------|
| text_to_toml | 277 | 512 |
| text_to_yaml | 235-790 | 512-1024 |
| csv_to_* | 1,039-1,059 | 1536 |
| json_to_* | 1,109-1,126 | 1536 |
| xml_to_* | 1,497-1,535 | 2048 |

### u-10bei系のフォーマット別平均トークン数

| フォーマット | 平均 | 推奨MAX_SEQ_LEN |
|-------------|------|----------------|
| csv | 301-316 | 512 |
| json | 328 | 512 |
| toml | 306-324 | 512 |
| xml | 350-355 | 512-768 |
| yaml | 302-318 | 512 |

全フォーマットで512トークンが適切（CoTを含めても短い）

---

**結論**: `SFT_MAX_SEQ_LEN=1024`がメモリとカバー率のバランスが最良。リソースに余裕があれば2048を推奨。
