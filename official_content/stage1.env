# 1. モデル・データセット関連
SFT_BASE_MODEL=Qwen/Qwen3-4B-Instruct-2507
SFT_DATASET_ID=daichira/structured-5k-mix-sft
SFT_OUT_LORA_DIR=~/workspace/2025_llm_comp_main/output/lora_structeval_t_qwen3_4b

# 複数データセットのMix（オプション）
# 使用例: SFT_DATASET_MIX='[{"id": "dataset1", "weight": 1.0, "split": "train"}, {"id": "dataset2", "weight": 2.0}]'
# SFT_DATASET_MIX=''

# Stage 1
SFT_MAX_SEQ_LEN=2048

SFT_LORA_R=8
SFT_LORA_ALPHA=32
SFT_LORA_DROPOUT=0.05
SFT_LORA_TARGET_MODULES=q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj

SFT_EPOCHS=1
SFT_MAX_STEPS=1500            # まずは短く“出力形式”だけ矯正（全量1epochより先にこれ）
SFT_PER_DEVICE_TRAIN_BS=1
SFT_GRAD_ACCUM=16             # 実効BS=16

SFT_LR=1e-4                   # 公式SFT例 :contentReference[oaicite:27]{index=27}
SFT_WARMUP_RATIO=0.05         # 公式SFT例 :contentReference[oaicite:28]{index=28}
SFT_WEIGHT_DECAY=0.0

SFT_MASK_COT=1
SFT_OUTPUT_MARKERS=Output:,OUTPUT:,Final:,Answer:,Result:,Response:
SFT_OUTPUT_LEARN_MODE=after_marker
SFT_USE_UPSAMPLING=0

# MLflow実験管理（オプション）
# MLFLOW_EXPERIMENT_NAME=llm-training-stage1
# MLflow UI起動: mlflow ui --backend-store-uri file://~/workspace/2025_llm_comp_main/mlruns --port 58000